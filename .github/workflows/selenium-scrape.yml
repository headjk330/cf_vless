name: Selenium Scrape Cloudflare IPs
on:
  # 可选触发方式：手动触发/定时触发（每15分钟一次，可调整）
  workflow_dispatch:  # 手动触发（在GitHub仓库“Actions”页点击运行）
  schedule:
    - cron: '*/15 * * * *'  # 定时触发，格式：分 时 日 月 周

jobs:
  scrape:
    runs-on: ubuntu-latest  # 使用Linux runner（无界面，需Headless模式）
    steps:
      - name: 1. 拉取仓库代码
        uses: actions/checkout@v4

      - name: 2. 安装Python环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'  # 指定Python版本

      - name: 3. 安装依赖包
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: 4. 安装Chrome浏览器（Linux）
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser  # 安装无界面Chrome

      - name: 5. 运行Selenium爬虫脚本
        run: python scrape_ips.py  # 执行爬虫脚本

      - name: 6. 保存结果（可选，将提取的IP保存为文件并上传）
        uses: actions/upload-artifact@v4
        with:
          name: cloudflare-ips-result
          path: ips_result.txt  # 脚本中需将结果写入该文件
